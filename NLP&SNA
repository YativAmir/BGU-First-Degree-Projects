Kendrick vs Drake: Analyzing Social Media Beef with NLP and Social Network Analysis
This repository contains the code and analysis for a project that explores the social media "beef" between rappers Kendrick Lamar and Drake. Using data from Reddit, we applied Natural Language Processing (NLP) and Social Network Analysis (SNA) techniques to better understand the dynamics of the online discourse surrounding this rivalry.

Project Overview
The project focuses on analyzing posts and comments from the subreddits related to Kendrick Lamar and Drake. We use NLP to preprocess and analyze the sentiment, keywords, and topic models in the discussions. Additionally, we employ SNA to visualize the relationships between users and to compute centrality measures to identify key figures in the online conversation.

Key Components:
Data Collection: We collected posts and comments from the subreddits r/KendrickLamar and r/Drizzy using the PRAW API.
Text Preprocessing: The collected data was cleaned, tokenized, and lemmatized to facilitate the analysis of keywords, sentiment, and topics.
Social Network Construction: We built a network graph where the nodes represent Reddit users and the edges represent interactions (replies and responses).
Centrality Metrics: We calculated centrality measures such as degree centrality and betweenness centrality to identify influential users.
Visualization: Graphs were generated to visualize the user interactions and topic distributions.
Repository Contents
NLP&SNA.py: The main script that collects Reddit data, processes the text, builds the social network, and performs network analysis and export functions.
Kendrick vs Drake Report.pdf: A detailed report summarizing the methodology, analysis, and findings of the project.
Installation
To run the project locally, clone this repository and install the required dependencies:

bash
Copy code
git clone https://github.com/yourusername/kendrick-vs-drake-nlp-sna.git
cd kendrick-vs-drake-nlp-sna
pip install -r requirements.txt
Requirements
praw: Python Reddit API Wrapper for collecting Reddit data.
networkx: For constructing and analyzing the social network.
pandas: For data manipulation.
nltk: For text preprocessing tasks like tokenization and lemmatization.
textblob: For sentiment analysis.
scikit-learn: For topic modeling.
matplotlib and wordcloud: For visualization.
Data Collection
To collect Reddit data, update the credentials in the NLP&SNA.py file with your own Reddit API credentials:

python
Copy code
reddit = praw.Reddit(
    client_id="your_client_id",
    client_secret="your_client_secret",
    user_agent="your_user_agent",
    username="your_username",
    password="your_password"
)
Run the data collection process by executing the script:

bash
Copy code
python NLP&SNA.py
The collected data will be saved as CSV files for further analysis.

Running the Analysis
Once the data is collected, the script will:

Preprocess the text by cleaning, tokenizing, and lemmatizing it.
Build a social network of interactions between users.
Perform network analysis to calculate centrality metrics.
Save the results as CSV files and display visualizations such as word clouds and sentiment distributions.
Results
Sentiment Analysis: Analyzes the overall sentiment in posts and comments.
Keyword Extraction: Identifies key words used in the beef between Kendrick and Drake.
Topic Modeling: Breaks down the discussions into underlying topics using LDA.
Network Analysis: Visualizes user interactions and highlights influential participants in the discussion.
Contribution
Feel free to contribute by submitting issues or pull requests. If you have any feedback or ideas for improving the analysis, weâ€™d love to hear from you!
